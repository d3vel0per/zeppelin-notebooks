{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573590602072_1319532471","id":"20191112-203002_322217420","dateCreated":"2019-11-12T20:30:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:206","text":"%sh\n# Checking environment variables\necho \"JAVA_HOME: $JAVA_HOME\"\necho \"SPARK_HOME: $SPARK_HOME\"\necho \"HADOOP_CONF_DIR: $HADOOP_CONF_DIR\"\necho \"PYTHON_HOME: $PYTHON_HOME\"","dateUpdated":"2019-11-12T20:30:16+0000","dateFinished":"2019-11-12T20:30:20+0000","dateStarted":"2019-11-12T20:30:16+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64\nSPARK_HOME: \nHADOOP_CONF_DIR: \nPYTHON_HOME: \n"}]}},{"text":"%python.python\nfrom datetime import timedelta, date\nimport random\n\n# Function to generate daterange\ndef daterange(start_date, end_date):\n    for n in range(int ((end_date - start_date).days)):\n        yield start_date + timedelta(n)\n\n# Will generate files for all business days of current week\nstart_date = date(2019, 11, 11)\nend_date = date(2019, 11, 16)\n\n# A few other constants\nstream = ['NY','LN','TK']\nbu = ['B01','B02','B03','B04','B05','B06','B07','B08','B09','B10']\naccount_list = ['A01','A02','A03','A04','A05','A06','A07','A08','A09','A10','A11','A12','A13','A14','A15','A16','A17','A18','A19','A20']\ncusip_list = ['C01','C02','C03','C04','C05','C06','C07','C08','C09','C10','C11','C12','C13','C14','C15','C16','C17','C18','C19','C20']\ncr_db_ind = ['CR','DB']\nbal_file_prefix = \"/notebook/data/billing-pyspark/bal_\"\npos_file_prefix = \"/notebook/data/billing-pyspark/pos_\"\n\n# Generate sample balance files\nfor single_date in daterange(start_date, end_date):\n    for i in range(0,10): # For each day we will generate 10 files\n        f = open(\"{}_{}_{}.csv\".format(bal_file_prefix,i,single_date.strftime(\"%Y-%m-%d\")),\"w\")\n        f.write(\"BSNS_DATE,STREAM,BU,ACCOUNT,CUSIP,CR_DB_IND,AMOUNT\\n\")\n        for j in range(0,1000): # Each file to have thousand random rows\n            f.write(\"{},{},{},{},{},{},{}\\n\".format(single_date.strftime(\"%Y-%m-%d\"),random.choice(stream),random.choice(bu),random.choice(account_list), random.choice(cusip_list), random.choice(cr_db_ind), random.randint(1,1000)))\n        f.close()\n\n# Generate sample position files\nfor single_date in daterange(start_date, end_date):\n    for i in range(0,10): # For each day we will generate 10 files\n        f = open(\"{}_{}_{}.csv\".format(pos_file_prefix,i,single_date.strftime(\"%Y-%m-%d\")),\"w\")\n        f.write(\"BSNS_DATE,STREAM,BU,ACCOUNT,CUSIP,LONG,SHORT\\n\")\n        for j in range(0,1000): # Each file to have thousand random rows\n            f.write(\"{},{},{},{},{},{},{}\\n\".format(single_date.strftime(\"%Y-%m-%d\"),random.choice(stream),random.choice(bu),random.choice(account_list),random.choice(cusip_list),random.randint(-1000,1000),random.randint(-1000,1000)))\n        f.close()","user":"anonymous","dateUpdated":"2019-11-12T20:53:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573590616772_661966839","id":"20191112-203016_575293751","dateCreated":"2019-11-12T20:30:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:331","dateFinished":"2019-11-12T20:53:59+0000","dateStarted":"2019-11-12T20:53:57+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\n\n# Check samples for verification\nbaldf = spark.read.csv(\"/notebook/data/billing-pyspark/bal_*\", header=True)\nbaldf.show(5)\n\nposdf = spark.read.csv(\"/notebook/data/billing-pyspark/pos_*\", header=True)\nposdf.show(5)","user":"anonymous","dateUpdated":"2019-11-12T20:59:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573590738174_-708823981","id":"20191112-203218_900622732","dateCreated":"2019-11-12T20:32:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:432","dateFinished":"2019-11-12T20:59:59+0000","dateStarted":"2019-11-12T20:59:55+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+------+---+-------+-----+---------+------+\n| BSNS_DATE|STREAM| BU|ACCOUNT|CUSIP|CR_DB_IND|AMOUNT|\n+----------+------+---+-------+-----+---------+------+\n|2019-11-14|    TK|B09|    A13|  C10|       CR|   543|\n|2019-11-14|    TK|B05|    A07|  C13|       CR|   845|\n|2019-11-14|    NY|B07|    A04|  C05|       CR|   970|\n|2019-11-14|    LN|B03|    A14|  C05|       CR|   900|\n|2019-11-14|    LN|B04|    A18|  C05|       CR|   492|\n+----------+------+---+-------+-----+---------+------+\nonly showing top 5 rows\n\n+----------+------+---+-------+-----+----+-----+\n| BSNS_DATE|STREAM| BU|ACCOUNT|CUSIP|LONG|SHORT|\n+----------+------+---+-------+-----+----+-----+\n|2019-11-15|    TK|B10|    A07|  C17|-309|  331|\n|2019-11-15|    TK|B02|    A15|  C15|-803| -230|\n|2019-11-15|    NY|B05|    A20|  C04| 345| -346|\n|2019-11-15|    TK|B07|    A20|  C03|-185|  -97|\n|2019-11-15|    NY|B10|    A02|  C13|-764|  378|\n+----------+------+---+-------+-----+----+-----+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.4:4040/jobs/job?id=22","http://172.17.0.4:4040/jobs/job?id=23","http://172.17.0.4:4040/jobs/job?id=24","http://172.17.0.4:4040/jobs/job?id=25","http://172.17.0.4:4040/jobs/job?id=26","http://172.17.0.4:4040/jobs/job?id=27","http://172.17.0.4:4040/jobs/job?id=28","http://172.17.0.4:4040/jobs/job?id=29"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\n\n# Check the implicit schema assumptions that spark made\nbaldf.printSchema()\nposdf.printSchema()","user":"anonymous","dateUpdated":"2019-11-12T21:07:02+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573592770443_1118108679","id":"20191112-210610_265597885","dateCreated":"2019-11-12T21:06:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:694","dateFinished":"2019-11-12T21:07:03+0000","dateStarted":"2019-11-12T21:07:02+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- BSNS_DATE: string (nullable = true)\n |-- STREAM: string (nullable = true)\n |-- BU: string (nullable = true)\n |-- ACCOUNT: string (nullable = true)\n |-- CUSIP: string (nullable = true)\n |-- CR_DB_IND: string (nullable = true)\n |-- AMOUNT: string (nullable = true)\n\nroot\n |-- BSNS_DATE: string (nullable = true)\n |-- STREAM: string (nullable = true)\n |-- BU: string (nullable = true)\n |-- ACCOUNT: string (nullable = true)\n |-- CUSIP: string (nullable = true)\n |-- LONG: string (nullable = true)\n |-- SHORT: string (nullable = true)\n\n"}]}},{"text":"%pyspark\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n\n# Define schema of the dataframes else implicit assumptions as shown above may not be always correct\nbal_labels = [\n    ('BSNS_DATE', DateType())\n    ,('STREAM', StringType())\n    ,('BU', StringType())\n    ,('ACCOUNT', StringType())\n    ,('CUSIP', StringType())\n    ,('CR_DB_IND', StringType())\n    ,('AMOUNT', IntegerType())\n    ]\n\npos_labels = [\n    ('BSNS_DATE', DateType())\n    ,('STREAM', StringType())\n    ,('BU', StringType())\n    ,('ACCOUNT', StringType())\n    ,('CUSIP', StringType())\n    ,('LONG', IntegerType())\n    ,('SHORT', IntegerType())\n    ]\n    \nbal_schema = StructType([StructField(x[0], x[1], True) for x in bal_labels])\npos_schema = StructType([StructField(x[0], x[1], True) for x in pos_labels])","user":"anonymous","dateUpdated":"2019-11-12T21:07:45+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573592395233_-2138344280","id":"20191112-205955_1824413722","dateCreated":"2019-11-12T20:59:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:561","dateFinished":"2019-11-12T21:07:46+0000","dateStarted":"2019-11-12T21:07:45+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\n\n# Use the new schema definations and reimport data\nbaldf = spark.read.csv(\"/notebook/data/billing-pyspark/bal_*\", header=True, schema=bal_schema)\nposdf = spark.read.csv(\"/notebook/data/billing-pyspark/pos_*\", header=True, schema=pos_schema)\nbaldf.printSchema()\nposdf.printSchema()","user":"anonymous","dateUpdated":"2019-11-12T21:09:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573592865796_-2100916574","id":"20191112-210745_592272283","dateCreated":"2019-11-12T21:07:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:794","dateFinished":"2019-11-12T21:09:54+0000","dateStarted":"2019-11-12T21:09:52+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- BSNS_DATE: date (nullable = true)\n |-- STREAM: string (nullable = true)\n |-- BU: string (nullable = true)\n |-- ACCOUNT: string (nullable = true)\n |-- CUSIP: string (nullable = true)\n |-- CR_DB_IND: string (nullable = true)\n |-- AMOUNT: integer (nullable = true)\n\nroot\n |-- BSNS_DATE: date (nullable = true)\n |-- STREAM: string (nullable = true)\n |-- BU: string (nullable = true)\n |-- ACCOUNT: string (nullable = true)\n |-- CUSIP: string (nullable = true)\n |-- LONG: integer (nullable = true)\n |-- SHORT: integer (nullable = true)\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.4:4040/jobs/job?id=30","http://172.17.0.4:4040/jobs/job?id=31"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\nfrom pyspark.sql.functions import when\nfrom pyspark.sql.functions import substring, column\nfrom pyspark.sql.types import IntegerType\n\n# Perform transformations and a very dumb business rule to apply as much commission as the ending digit of the account ;P\ntransbaldf = baldf.withColumn('SIGNED_AMOUNT', when(baldf['CR_DB_IND'] == 'DB', -1*baldf['AMOUNT']).otherwise(baldf['AMOUNT'])).withColumn('COMMISSION', substring(baldf['ACCOUNT'], -1, 1).cast(IntegerType()))\ntransbaldf.show(5)\n\ntransposdf = posdf.withColumn('NET', posdf['LONG']+posdf['SHORT'])\ntransposdf.show(5)","user":"anonymous","dateUpdated":"2019-11-12T21:17:57+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573592992958_1279577823","id":"20191112-210952_1248412593","dateCreated":"2019-11-12T21:09:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:875","dateFinished":"2019-11-12T21:17:58+0000","dateStarted":"2019-11-12T21:17:58+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+------+---+-------+-----+---------+------+-------------+----------+\n| BSNS_DATE|STREAM| BU|ACCOUNT|CUSIP|CR_DB_IND|AMOUNT|SIGNED_AMOUNT|COMMISSION|\n+----------+------+---+-------+-----+---------+------+-------------+----------+\n|2019-11-14|    TK|B09|    A13|  C10|       CR|   543|          543|         3|\n|2019-11-14|    TK|B05|    A07|  C13|       CR|   845|          845|         7|\n|2019-11-14|    NY|B07|    A04|  C05|       CR|   970|          970|         4|\n|2019-11-14|    LN|B03|    A14|  C05|       CR|   900|          900|         4|\n|2019-11-14|    LN|B04|    A18|  C05|       CR|   492|          492|         8|\n+----------+------+---+-------+-----+---------+------+-------------+----------+\nonly showing top 5 rows\n\n+----------+------+---+-------+-----+----+-----+-----+\n| BSNS_DATE|STREAM| BU|ACCOUNT|CUSIP|LONG|SHORT|  NET|\n+----------+------+---+-------+-----+----+-----+-----+\n|2019-11-15|    TK|B10|    A07|  C17|-309|  331|   22|\n|2019-11-15|    TK|B02|    A15|  C15|-803| -230|-1033|\n|2019-11-15|    NY|B05|    A20|  C04| 345| -346|   -1|\n|2019-11-15|    TK|B07|    A20|  C03|-185|  -97| -282|\n|2019-11-15|    NY|B10|    A02|  C13|-764|  378| -386|\n+----------+------+---+-------+-----+----+-----+-----+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.4:4040/jobs/job?id=33","http://172.17.0.4:4040/jobs/job?id=34"],"interpreterSettingId":"spark"}}},{"text":"%pyspark\nfrom pyspark.sql.functions import sum\n\n# Check sample aggregation results\naggbaldf = transbaldf.select('BSNS_DATE','ACCOUNT','CUSIP','SIGNED_AMOUNT','COMMISSION').groupBy('BSNS_DATE','ACCOUNT','CUSIP').sum('SIGNED_AMOUNT','COMMISSION')\naggposdf = transposdf.select('BSNS_DATE','ACCOUNT','CUSIP','LONG','SHORT','NET').groupBy('BSNS_DATE','ACCOUNT','CUSIP').sum('LONG','SHORT','NET')\naggbaldf.show(5)\naggposdf.show(5)\n\n# Create views for visualization\naggbaldf.createOrReplaceTempView(\"balances\")\naggposdf.createOrReplaceTempView(\"positions\")","user":"anonymous","dateUpdated":"2019-11-12T21:27:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573593282197_-228210246","id":"20191112-211442_153118899","dateCreated":"2019-11-12T21:14:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:992","dateFinished":"2019-11-12T21:27:51+0000","dateStarted":"2019-11-12T21:27:48+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+-------+-----+------------------+---------------+\n| BSNS_DATE|ACCOUNT|CUSIP|sum(SIGNED_AMOUNT)|sum(COMMISSION)|\n+----------+-------+-----+------------------+---------------+\n|2019-11-14|    A12|  C03|              5031|             72|\n|2019-11-14|    A06|  C11|             -3312|            162|\n|2019-11-14|    A06|  C20|             -1555|            156|\n|2019-11-12|    A17|  C10|             -2713|            168|\n|2019-11-11|    A09|  C01|                70|            180|\n+----------+-------+-----+------------------+---------------+\nonly showing top 5 rows\n\n+----------+-------+-----+---------+----------+--------+\n| BSNS_DATE|ACCOUNT|CUSIP|sum(LONG)|sum(SHORT)|sum(NET)|\n+----------+-------+-----+---------+----------+--------+\n|2019-11-14|    A06|  C20|      974|      4571|    5545|\n|2019-11-14|    A06|  C11|    -1308|     -3236|   -4544|\n|2019-11-12|    A19|  C07|     -858|       267|    -591|\n|2019-11-12|    A17|  C10|     -352|      1094|     742|\n|2019-11-12|    A15|  C09|    -1410|     -1284|   -2694|\n+----------+-------+-----+---------+----------+--------+\nonly showing top 5 rows\n\n"}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.4:4040/jobs/job?id=37","http://172.17.0.4:4040/jobs/job?id=38"],"interpreterSettingId":"spark"}}},{"text":"%spark.sql\nSELECT * FROM balances WHERE account = 'A01' limit 5","user":"anonymous","dateUpdated":"2019-11-12T21:33:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"stackedAreaChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"BSNS_DATE":"string","ACCOUNT":"string","CUSIP":"string","sum(SIGNED_AMOUNT)":"string","sum(COMMISSION)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"lineChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"},"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"BSNS_DATE","index":0,"aggr":"sum"}],"groups":[{"name":"CUSIP","index":2,"aggr":"sum"}],"values":[{"name":"sum(SIGNED_AMOUNT)","index":3,"aggr":"sum"},{"name":"sum(COMMISSION)","index":4,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573593688146_597892653","id":"20191112-212128_518614076","dateCreated":"2019-11-12T21:21:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1147","dateFinished":"2019-11-12T21:31:26+0000","dateStarted":"2019-11-12T21:31:25+0000","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"BSNS_DATE\tACCOUNT\tCUSIP\tsum(SIGNED_AMOUNT)\tsum(COMMISSION)\n2019-11-11\tA01\tC17\t3680\t19\n2019-11-13\tA01\tC03\t-3318\t34\n2019-11-12\tA01\tC17\t-874\t24\n2019-11-13\tA01\tC10\t-882\t20\n2019-11-13\tA01\tC01\t1027\t17\n"},{"type":"TEXT","data":""}]},"runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://172.17.0.4:4040/jobs/job?id=40","http://172.17.0.4:4040/jobs/job?id=41","http://172.17.0.4:4040/jobs/job?id=42"],"interpreterSettingId":"spark"}}},{"text":"%spark.sql\n","user":"anonymous","dateUpdated":"2019-11-12T21:29:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1573594154743_836966344","id":"20191112-212914_235135123","dateCreated":"2019-11-12T21:29:14+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1382"}],"name":"billing-pyspark","id":"2ETFWUFKC","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"python:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}